{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> Explanation of the statsmodels summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video Explanation : https://youtu.be/1mWFhwgVvjk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a concrete regression dataset\n",
    "#https://anaconda.org/DistrictDataLabs/yellowbrick\n",
    "from yellowbrick.datasets import load_concrete\n",
    "# https://archive.ics.uci.edu/ml/datasets/concrete+compressive+strength\n",
    "X_c, y_c = load_concrete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>slag</th>\n",
       "      <th>ash</th>\n",
       "      <th>water</th>\n",
       "      <th>splast</th>\n",
       "      <th>coarse</th>\n",
       "      <th>fine</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cement   slag  ash  water  splast  coarse   fine  age\n",
       "0   540.0    0.0  0.0  162.0     2.5  1040.0  676.0   28\n",
       "1   540.0    0.0  0.0  162.0     2.5  1055.0  676.0   28\n",
       "2   332.5  142.5  0.0  228.0     0.0   932.0  594.0  270\n",
       "3   332.5  142.5  0.0  228.0     0.0   932.0  594.0  365\n",
       "4   198.6  132.4  0.0  192.0     0.0   978.4  825.5  360"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    79.986111\n",
       "1    61.887366\n",
       "2    40.269535\n",
       "3    41.052780\n",
       "4    44.296075\n",
       "Name: strength, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train and test data\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X_c, y_c, test_size=0.2, random_state=42)\n",
    "# first artificially add intercept to X\n",
    "import statsmodels.api as sm\n",
    "X_c_s = sm.add_constant(X_c)\n",
    "slr_c = sm.OLS(y_c,X_c_s)\n",
    "slr_model_c = slr_c.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>strength</td>     <th>  R-squared:         </th> <td>   0.615</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.612</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   204.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 14 Jun 2021</td> <th>  Prob (F-statistic):</th> <td>6.76e-206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:30:17</td>     <th>  Log-Likelihood:    </th> <td> -3869.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1030</td>      <th>  AIC:               </th> <td>   7756.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1021</td>      <th>  BIC:               </th> <td>   7800.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>  <td>  -23.1638</td> <td>   26.588</td> <td>   -0.871</td> <td> 0.384</td> <td>  -75.338</td> <td>   29.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cement</th> <td>    0.1198</td> <td>    0.008</td> <td>   14.110</td> <td> 0.000</td> <td>    0.103</td> <td>    0.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>slag</th>   <td>    0.1038</td> <td>    0.010</td> <td>   10.245</td> <td> 0.000</td> <td>    0.084</td> <td>    0.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ash</th>    <td>    0.0879</td> <td>    0.013</td> <td>    6.988</td> <td> 0.000</td> <td>    0.063</td> <td>    0.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>water</th>  <td>   -0.1503</td> <td>    0.040</td> <td>   -3.741</td> <td> 0.000</td> <td>   -0.229</td> <td>   -0.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>splast</th> <td>    0.2907</td> <td>    0.093</td> <td>    3.110</td> <td> 0.002</td> <td>    0.107</td> <td>    0.474</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>coarse</th> <td>    0.0180</td> <td>    0.009</td> <td>    1.919</td> <td> 0.055</td> <td>   -0.000</td> <td>    0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fine</th>   <td>    0.0202</td> <td>    0.011</td> <td>    1.883</td> <td> 0.060</td> <td>   -0.001</td> <td>    0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>    <td>    0.1142</td> <td>    0.005</td> <td>   21.046</td> <td> 0.000</td> <td>    0.104</td> <td>    0.125</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 5.379</td> <th>  Durbin-Watson:     </th> <td>   1.281</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.068</td> <th>  Jarque-Bera (JB):  </th> <td>   5.305</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.174</td> <th>  Prob(JB):          </th> <td>  0.0705</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.045</td> <th>  Cond. No.          </th> <td>1.06e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.06e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:               strength   R-squared:                       0.615\n",
       "Model:                            OLS   Adj. R-squared:                  0.612\n",
       "Method:                 Least Squares   F-statistic:                     204.3\n",
       "Date:                Mon, 14 Jun 2021   Prob (F-statistic):          6.76e-206\n",
       "Time:                        10:30:17   Log-Likelihood:                -3869.0\n",
       "No. Observations:                1030   AIC:                             7756.\n",
       "Df Residuals:                    1021   BIC:                             7800.\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        -23.1638     26.588     -0.871      0.384     -75.338      29.010\n",
       "cement         0.1198      0.008     14.110      0.000       0.103       0.136\n",
       "slag           0.1038      0.010     10.245      0.000       0.084       0.124\n",
       "ash            0.0879      0.013      6.988      0.000       0.063       0.113\n",
       "water         -0.1503      0.040     -3.741      0.000      -0.229      -0.071\n",
       "splast         0.2907      0.093      3.110      0.002       0.107       0.474\n",
       "coarse         0.0180      0.009      1.919      0.055      -0.000       0.036\n",
       "fine           0.0202      0.011      1.883      0.060      -0.001       0.041\n",
       "age            0.1142      0.005     21.046      0.000       0.104       0.125\n",
       "==============================================================================\n",
       "Omnibus:                        5.379   Durbin-Watson:                   1.281\n",
       "Prob(Omnibus):                  0.068   Jarque-Bera (JB):                5.305\n",
       "Skew:                          -0.174   Prob(JB):                       0.0705\n",
       "Kurtosis:                       3.045   Cond. No.                     1.06e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.06e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slr_model_c.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:blue\"> Dep. Variable** : is the target(depndent) variable the model is learning (column \"strenght\" in this model).\n",
    "\n",
    "**<span style=\"color:blue\"> Model** :  is the Ordinary Least Squares as we use smf.ols function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:blue\"> Df Residuals:** another name is Degrees of Freedom. This is calculated in the form of ‘n-k-1’ or (number of observations-number of predicting variables-1). \n",
    "\n",
    "**<span style=\"color:blue\">Df Model:** numbers our predicting variables.\n",
    "    \n",
    "The degrees of freedom df is equal to the sample size minus the number of parameters we’re trying to estimate.\n",
    "\n",
    "For example, if we’re estimating 2 parameters β0 and β1 as in:\n",
    "\n",
    "Y = β0 + β1X + ε\n",
    "\n",
    "Then, df = n – 2\n",
    "\n",
    "If we’re estimating 3 parameters, as in:\n",
    "\n",
    "Y = β0 + β1X1 + β2X2 + ε\n",
    "\n",
    "Then, df = n – 3\n",
    "\n",
    "**<span style=\"color:blue\">Covariance :** Type is listed as nonrobust. Covariance is a measure of how two variables are linked in a positive or negative manner, and a robust covariance is one that is calculated in a way to minimize or eliminate variables, which is not the case here. Robust covariance methods are based on the fact that outliers lead to an increase of the values  and making the spread of the data apparently larger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:blue\">R-squared** : R-squared is the measurement of how much of the independent variable is explained by changes in our dependent variables.Note that adding features to the model won’t decrease R-squared. This is because the model can find the same fit as before when more features are added. More often the R-squared increases by chance when adding features.\n",
    "Here R-squared value is 0.615, then it means that the independent variables explain 61.5% of the variation in the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:blue\">Adjusted R-squared** : Linear regression has the quality that your model’s R-squared value will never go down with additional variables, only equal or higher. Therefore, your model could look more accurate with multiple variables even if they are poorly contributing. The adjusted R-squared penalizes the R-squared formula based on the number of variables, therefore a lower adjusted score may be telling you some variables are not contributing to your model’s R-squared properly. This property of Adjusted R-squared may be used to find the features that give the best accuracy. Adj. R-squared is on the range between 0 to 1, where 1 indicates that the model explains all the variability of the response data around its mean.\n",
    "sklearn hasn’t got a function for calculating Adjusted R-squared as it also takes the number of samples and features. We can calculate it with the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_r2(r2, n_samples, n_features):\n",
    "    return 1-(1-r2) * (n_samples-1) / (n_samples-n_features-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, high Adjusted R-squared doesn’t mean that your model is good. We need to check the residual plot when fitting a regression model. One of the assumptions of Linear Regression is Homoscedasticity, which means that the variance of residual is the same for any value of X. I am going to write about residual plots in my next article about regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:blue\">F-statistic :** \n",
    "- The F-test of overall significance indicates whether your linear regression model provides a better fit to the data than a model that contains no independent variables.This type of model is also known as an intercept-only model.For the model with no independent variables, the intercept-only model, all of the model’s predictions equal the mean of the dependent variable. Consequently, if the overall F-test is statistically significant, your model’s predictions are an improvement over using the mean.\n",
    "\n",
    "- The F-test for overall significance has the following two hypotheses:\n",
    "  - The null hypothesis states that the model with no independent variables fits the data as well as your model.\n",
    "  - The alternative hypothesis says that your model fits the data better than the intercept-only model.\n",
    "\n",
    "https://statisticsbyjim.com/regression/interpret-f-test-overall-significance-regression/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:blue\">Prob (F-Statistic) :** uses this number to tell you the accuracy of the null hypothesis, or whether it is accurate that your variables’ effect is 0. In this case, it is telling us 0.0% chance of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(6.76e-206,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:blue\">Log-likelihood :** \n",
    "Likelihood Ratio test (often termed as LR test) is a test to compare two models, concentrating on the improvement with respect to likelihood value. If we keep on adding predictor variables to a linear model, R-square will improve. This holds true for model likelihood value as well. But, the objective is to check if the improvement in likelihood is good enough or not!\n",
    "\n",
    "we have a data set with two variables, X and Y. You have fitted a regression equation between the two and got estimates or coefficients. Now, the likelihood is a measure that tells you how likely is that you will get a dataset like what you have, given the regression equation.\n",
    "\n",
    "So, higher the value of likelihood, better is the fit of the model. once a regression model is fit, we may like to measure the likelihood of the estimates, for which we look at the log of the likelihood value and call it Log Likelihood.\n",
    "\n",
    "It is used to compare coefficient values for each variable in the process of creating the model. \n",
    "Log Likelihood value is a measure of goodness of fit for any model. Higher the value, better is the model.\n",
    "\n",
    "We should remember that Log Likelihood can lie between -Inf to +Inf. Hence, the absolute look at the value cannot give any indication. We can only compare the Log Likelihood values between multiple models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:blue\">AIC and BIC :** are both used to compare the efficiency of models in the process of linear regression, using a penalty system for measuring multiple variables. These numbers are used for feature selection of variables.\n",
    "\n",
    "https://medium.com/swlh/what-do-we-see-with-aic-bic-57b3e12685d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:blue\">coefficients**\n",
    "\n",
    "The sign of a coefficient tells us whether there is a positive or negative correlation between a feature and a target variable.The positive coefficient indicates when the feature increases, the mean of the target also increases. A negative coefficient indicates as the feature value decreases, the target tends to decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:blue\"><span style=\"color:blue\">std error :** The standard error is an estimate of the standard deviation of the coefficient, the amount it varies across cases. It can be thought of as a measure of the precision with which the regression coefficient is measured. The standard error of the coefficient is always positive.The smaller the standard error, the more precise the estimate. \n",
    "\n",
    "Dividing the coefficient by its standard error calculates a t-value.If the p-value associated with this t-statistic is less than your alpha level, you conclude that the coefficient is significantly different from zero.\n",
    "\n",
    "The standard error of the 'cement' coefficient is smaller than that of 'fine'.Therefore, your model was able to stimate the coefficient for 'cement'with greater precision. In fact, the standard error of the 'fine' coefficient is about the sameclose to the value of the coefficient itself, so the t-value of 1.883 is too small to declare statistical significance. The resulting p-value is greater than common levels of α(0.05), so that you cannot conclude this\n",
    "coefficient differs from zero.You can remove the 'fine' variable from your regression model and continue the analysis.\n",
    "    \n",
    "https://support.minitab.com/en-us/minitab/18/help-and-how-to/modeling-statistics/regression/supporting-topics/regression-models/what-is-the-standard-error-of-the-coefficient/\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:blue\">The t :** is related and is a measurement of the precision with which the coefficient was measured. A low std error compared to a high coefficient produces a high t statistic, which signifies a high significance for your coefficient.\n",
    "    \n",
    "**<span style=\"color:blue\">P>|t| :** is one of the most important statistics in the summary. The p-value for each independent variable tests the null hypothesis that the variable has no correlation with the dependent variable. If there is no correlation, there is no association between the changes in the independent variable and the shifts in the dependent variable.\n",
    "    \n",
    "uses the following null and alternative hypotheses:\n",
    "\n",
    "- The null hypothesis (H0): variable has no correlation with the dependent variable.\n",
    "- The alternative hypothesis: (Ha): variable has correlation with the dependent variable.\n",
    "\n",
    " - If p-value < level of significance (0.05); then null hypothesis is rejected.\n",
    " - If p-value > level of significance (0.05); then we fail to reject the null hypothesis.\n",
    "    \n",
    "https://statisticsbyjim.com/regression/interpret-coefficients-p-values-regression/\n",
    "\n",
    "**<span style=\"color:blue\">[0.025 and 0.975] :** are both measurements of values of our coefficients within 95% of our data, or within two standard deviations. Outside of these values can generally be considered outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:blue\">Omnibus :** describes the normalcy of the distribution of our residuals using skew and kurtosis as measurements. A 0 would indicate perfect normalcy. \n",
    "\n",
    "**<span style=\"color:blue\">Prob(Omnibus) :** is a statistical test measuring the probability the residuals are normally distributed. A 1 would indicate perfectly normal distribution. \n",
    "\n",
    "**<span style=\"color:blue\">Skew :** is a measurement of symmetry in our data, with 0 being perfect symmetry. \n",
    "\n",
    "**<span style=\"color:blue\">Kurtosis :** measures the peakiness of our data, or its concentration around 0 in a normal curve. Higher kurtosis implies fewer outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:blue\">Durbin-Watson :** is a measurement for autocorrelation.Given the statistical value of 1.28, the test provides evidence that there is less positive autocorrelation present and it means that residual error terms has very less positive autocorrelation and is little bit dependent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\"> Durbin-Watson to test the autocorrelation in residuals**\n",
    "    \n",
    "A common method of testing for autocorrelation is the Durbin-Watson test. \n",
    "    \n",
    "Look for Durbin – Watson (DW) statistic.It must lie between 0 and 4. \n",
    " - If DW = 2, or close to it, implies no autocorrelation\n",
    " - 0 < DW < 2 implies positive autocorrelation \n",
    " - while 2 < DW < 4 indicates negative autocorrelation\n",
    "    \n",
    "Also, we can see residual vs time plot and look for the seasonal or correlated pattern in residual values in time series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2814906694343284"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first artificially add intercept to X\n",
    "X_c_s = sm.add_constant(X_c)\n",
    "slr_c = sm.OLS(y_c,X_c_s)\n",
    "slr_model_c = slr_c.fit()\n",
    "from statsmodels.compat import lzip\n",
    "import statsmodels\n",
    "statsmodels.stats.stattools.durbin_watson(slr_model_c.resid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the statistical value of 1.28, the test provides evidence that there is less positive autocorrelation present and it means that residual error terms has very less positive autocorrelation and is little bit dependent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:blue\">Jarque-Bera (JB) and Prob(JB) :** are alternate methods of measuring the same value as Omnibus and Prob(Omnibus) using skewness and kurtosis. We use these values to confirm each other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\"> Jarque-Bera Statistical test - To test Residuals are normally distributed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Jarque-Bera', 5.305288452007964),\n",
       " ('JBpvalue', 0.07046464206229237),\n",
       " ('Skew', -0.1743574625075855),\n",
       " ('Kurtosis', 3.0449029260620804)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first artificially add intercept to X\n",
    "#import statsmodels.stats.api as sms\n",
    "X_c_s = sm.add_constant(X_c)\n",
    "slr_c = sm.OLS(y_c,X_c_s)\n",
    "slr_model_c = slr_c.fit()\n",
    "name = ['Jarque-Bera', 'JBpvalue', 'Skew', 'Kurtosis']\n",
    "from statsmodels.compat import lzip\n",
    "import statsmodels\n",
    "test = statsmodels.stats.api.jarque_bera(slr_model_c.resid)\n",
    "lzip(name, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1030, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_c_s.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JB = n/6(S^2 + 1/4(K-3)^2)\n",
    "\n",
    "where n is the number of data points, S is the sample skewness, and K is the sample kurtosis of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Jarque-Bera test uses the following null and alternative hypotheses:\n",
    "\n",
    "- The null hypothesis (H0): Residuals are normally distributed.\n",
    "- The alternative hypothesis: (Ha): Residuals are not normally distributed.\n",
    "\n",
    " - If p-value < level of significance (0.05); then null hypothesis is rejected.\n",
    " - If p-value > level of significance (0.05); then we fail to reject the null hypothesis.\n",
    "\n",
    "In this example, the Jarque-Bera statistic for the test is 5.30 and the corresponding p-value is 0.0704. \n",
    "Because this p-value is greater than 0.05, we will accept the null hypothesis. We do not have sufficient evidence to say that Residuals are not normally distributed in the regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:blue\">Condition number :** it is used as a diagnostic for multicollinearity. Multicollinearity is strongly implied by a high condition number. Multicollinearity a term to describe two or more independent variables that are strongly related to each other and are falsely affecting our predicted variable by redundancy.\n",
    "\n",
    "**<span style=\"color:red\"> Uisng Condition number to check the Multicollinearity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1.06e+05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(X_c.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>slag</th>\n",
       "      <th>ash</th>\n",
       "      <th>water</th>\n",
       "      <th>splast</th>\n",
       "      <th>coarse</th>\n",
       "      <th>fine</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cement</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.275193</td>\n",
       "      <td>-0.397475</td>\n",
       "      <td>-0.081544</td>\n",
       "      <td>0.092771</td>\n",
       "      <td>-0.109356</td>\n",
       "      <td>-0.222720</td>\n",
       "      <td>0.081947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slag</th>\n",
       "      <td>-0.275193</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.323569</td>\n",
       "      <td>0.107286</td>\n",
       "      <td>0.043376</td>\n",
       "      <td>-0.283998</td>\n",
       "      <td>-0.281593</td>\n",
       "      <td>-0.044246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ash</th>\n",
       "      <td>-0.397475</td>\n",
       "      <td>-0.323569</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.257044</td>\n",
       "      <td>0.377340</td>\n",
       "      <td>-0.009977</td>\n",
       "      <td>0.079076</td>\n",
       "      <td>-0.154370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>-0.081544</td>\n",
       "      <td>0.107286</td>\n",
       "      <td>-0.257044</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.657464</td>\n",
       "      <td>-0.182312</td>\n",
       "      <td>-0.450635</td>\n",
       "      <td>0.277604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>splast</th>\n",
       "      <td>0.092771</td>\n",
       "      <td>0.043376</td>\n",
       "      <td>0.377340</td>\n",
       "      <td>-0.657464</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.266303</td>\n",
       "      <td>0.222501</td>\n",
       "      <td>-0.192717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coarse</th>\n",
       "      <td>-0.109356</td>\n",
       "      <td>-0.283998</td>\n",
       "      <td>-0.009977</td>\n",
       "      <td>-0.182312</td>\n",
       "      <td>-0.266303</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.178506</td>\n",
       "      <td>-0.003016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fine</th>\n",
       "      <td>-0.222720</td>\n",
       "      <td>-0.281593</td>\n",
       "      <td>0.079076</td>\n",
       "      <td>-0.450635</td>\n",
       "      <td>0.222501</td>\n",
       "      <td>-0.178506</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.156094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.081947</td>\n",
       "      <td>-0.044246</td>\n",
       "      <td>-0.154370</td>\n",
       "      <td>0.277604</td>\n",
       "      <td>-0.192717</td>\n",
       "      <td>-0.003016</td>\n",
       "      <td>-0.156094</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cement      slag       ash     water    splast    coarse      fine  \\\n",
       "cement  1.000000 -0.275193 -0.397475 -0.081544  0.092771 -0.109356 -0.222720   \n",
       "slag   -0.275193  1.000000 -0.323569  0.107286  0.043376 -0.283998 -0.281593   \n",
       "ash    -0.397475 -0.323569  1.000000 -0.257044  0.377340 -0.009977  0.079076   \n",
       "water  -0.081544  0.107286 -0.257044  1.000000 -0.657464 -0.182312 -0.450635   \n",
       "splast  0.092771  0.043376  0.377340 -0.657464  1.000000 -0.266303  0.222501   \n",
       "coarse -0.109356 -0.283998 -0.009977 -0.182312 -0.266303  1.000000 -0.178506   \n",
       "fine   -0.222720 -0.281593  0.079076 -0.450635  0.222501 -0.178506  1.000000   \n",
       "age     0.081947 -0.044246 -0.154370  0.277604 -0.192717 -0.003016 -0.156094   \n",
       "\n",
       "             age  \n",
       "cement  0.081947  \n",
       "slag   -0.044246  \n",
       "ash    -0.154370  \n",
       "water   0.277604  \n",
       "splast -0.192717  \n",
       "coarse -0.003016  \n",
       "fine   -0.156094  \n",
       "age     1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_c.corr()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
